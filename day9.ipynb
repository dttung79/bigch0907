{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"print('Hello Python')\\n\", \"a = int(input('Enter a: '))\\n\", 'print(a)']\n",
      "print('Hello Python')\n",
      "a = int(input('Enter a: '))\n",
      "print(a)\n"
     ]
    }
   ],
   "source": [
    "f = open('hello.py', 'r')\n",
    "content = f.readlines()\n",
    "print(content)\n",
    "\n",
    "for line in content:\n",
    "    print(line.strip())\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"print('Hello Python')\\n\", \"a = int(input('Enter a: '))\\n\", 'print(a)']\n"
     ]
    }
   ],
   "source": [
    "with open('hello.py', 'r') as f:\n",
    "    content = f.readlines()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Triboro Bridge and Tunnel Authority\n",
      "The Metropolitan Transit Authority\n",
      "The Port Authority of New York and New Jersey\n"
     ]
    }
   ],
   "source": [
    "# TODO: read agencies.txt, find all agencies that has Authority in name.\n",
    "with open('Datasets/agencies.txt', 'r') as f:\n",
    "    content = f.readlines()\n",
    "    for line in content:\n",
    "        if 'Authority' in line:\n",
    "            print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Triboro Bridge and Tunnel Authority\n",
      "The Metropolitan Transit Authority\n",
      "The Port Authority of New York and New Jersey\n"
     ]
    }
   ],
   "source": [
    "# read agencies line by line\n",
    "try: \n",
    "    f = open('Datasets/agencies.txt', 'r')\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        if 'Authority' in line:\n",
    "            print(line.strip())\n",
    "        line = f.readline()\n",
    "    f.close()\n",
    "except FileNotFoundError:\n",
    "    print('File not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: count number of lines & number of word in agencies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines:  6\n",
      "Number of words:  30\n"
     ]
    }
   ],
   "source": [
    "with open('Datasets/agencies.txt', 'r') as f:\n",
    "    content = f.readlines()\n",
    "    print('Number of lines: ', len(content))\n",
    "    count = 0\n",
    "    for line in content:\n",
    "        count += len(line.split()) # count number of words in a line\n",
    "    print('Number of words: ', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: read & print name, email of authors in authors.txt\n",
    "# For example: \n",
    "# Paul Bakaul    : paul.bakaus@gmail.com\n",
    "# ERichard Worth : rdworth@gmail.com\n",
    "\n",
    "with open('Datasets/authors.txt', 'r') as f:\n",
    "    for i in range(3):\n",
    "        next(f) # skip 3 first lines\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        name, email = line.split('<')\n",
    "        name = name.strip() \n",
    "        email = email.strip()[:-1]\n",
    "        if '@' in email:\n",
    "            print(f'{name:20} : {email}')\n",
    "        line = f.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times:  [0.0, 0.5, 0.7]\n",
      "Heights:  [180.0, 185.0, 192.0]\n",
      "Uncertainties:  [3.5, 4.5, 5.2]\n"
     ]
    }
   ],
   "source": [
    "# Read falling.txt, store data into 3 lists: times, heights, uncertainties\n",
    "with open('Datasets/falling.txt', 'r') as f:\n",
    "    times = []\n",
    "    heights = []\n",
    "    uncertainties = []\n",
    "    lines = f.readlines()[5:] # read all lines & skip 5 first lines\n",
    "    for line in lines:\n",
    "        _, t, h, u = line.split()\n",
    "        times.append(float(t))\n",
    "        heights.append(float(h))\n",
    "        uncertainties.append(float(u))\n",
    "\n",
    "print('Times: ', times)\n",
    "print('Heights: ', heights)\n",
    "print('Uncertainties: ', uncertainties)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times:  [0.  0.5 0.7]\n",
      "Heights:  [180. 185. 192.]\n",
      "Uncertainties:  [3.5 4.5 5.2]\n",
      "[[  0.  180.    3.5]\n",
      " [  0.5 185.    4.5]\n",
      " [  0.7 192.    5.2]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "times, heights, uncertainties = np.loadtxt('Datasets/falling.txt',  # file name\n",
    "                                            skiprows=5,             # skip 5 first lines\n",
    "                                            usecols=(1,2,3),        # use columns 1, 2, 3\n",
    "                                            unpack=True)            # unpack data into 3 arrays\n",
    "print('Times: ', times)\n",
    "print('Heights: ', heights)\n",
    "print('Uncertainties: ', uncertainties)\n",
    "\n",
    "data = np.loadtxt('Datasets/falling.txt',  # file name\n",
    "                                            skiprows=5,             # skip 5 first lines\n",
    "                                            usecols=(1,2,3))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinction students: ['Lan', 'Hung']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Read grades.txt, print Distinction students (average >= 8.0)\n",
    "data = np.loadtxt('Datasets/grades.txt', skiprows=5, dtype=str)\n",
    "print('Distinction students:', [row[0] for row in data \n",
    "                                    if (float(row[1]) + float(row[2]) + float(row[3]))/3 >= 8.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data:\n",
    "    if (float(row[1]) + float(row[2]) + float(row[3]))/3 >= 8.0:\n",
    "        print(row[0], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, maths, liters, english = np.loadtxt('Datasets/grades.txt', skiprows=5, dtype=str, unpack=True)\n",
    "for i in range(len(names)):\n",
    "    if (float(maths[i]) + float(liters[i]) + float(english[i]))/3 >= 8.0:\n",
    "        print(names[i], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in (row[0] for row in data if (float(row[1]) + float(row[2]) + float(row[3]))/3 >= 8.0):\n",
    "    print(name, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lan Hung "
     ]
    }
   ],
   "source": [
    "for name in (names[i] for i in range(len(names)) \n",
    "                        if (float(maths[i]) + float(liters[i]) + float(english[i]))/3 >= 8.0):\n",
    "    print(name, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBH17538: Le Minh Huong, 6.5\n",
      "GCH16025: Bui Phuong Nam, 0\n",
      "GCH16336: Nguyen The Dat, 6.5\n",
      "GCH16388: Pham Minh Thang, 6.5\n",
      "GCH16573: Do Duy Tung, 6.5\n"
     ]
    }
   ],
   "source": [
    "# Read csv file using numpy.loadtxt\n",
    "codes, names, grades = np.loadtxt('Datasets/gradebook.csv', delimiter=',', \n",
    "                                            skiprows=1, usecols= (2, 3, 4), dtype=str, unpack=True)\n",
    "for i in range(len(codes)):\n",
    "        print(f'{codes[i]}: {names[i]}, {grades[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBH17538: Le Minh Huong, 6.5, <class 'str'>\n",
      "GCH16025: Bui Phuong Nam, 0, <class 'str'>\n",
      "GCH16336: Nguyen The Dat, 6.5, <class 'str'>\n",
      "GCH16388: Pham Minh Thang, 6.5, <class 'str'>\n",
      "GCH16573: Do Duy Tung, 6.5, <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('Datasets/gradebook.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader) # skip header\n",
    "    for row in reader:\n",
    "        print(f'{row[2]}: {row[3]}, {row[4]}, {type(row[4])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
